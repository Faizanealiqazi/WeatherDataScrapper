{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObeMtUw9mfqp7GlFq6femw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Faizanealiqazi/WeatherDataScrapper/blob/main/WeatherDataScrapping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "THmvS9og-hYI"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "from datetime import datetime, timedelta"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dates = []\n",
        "start_date = datetime.strptime(\"01-1942\", \"%m-%Y\")\n",
        "end_date = datetime.strptime(\"12-2023\", \"%m-%Y\")\n",
        "current_date = start_date\n",
        "\n",
        "while current_date <= end_date:\n",
        "    dates.append(current_date.strftime(\"%m-%Y\"))\n",
        "    if current_date.month == 12:\n",
        "        current_date = current_date.replace(year=current_date.year + 1, month=1)\n",
        "    else:\n",
        "        current_date = current_date.replace(month=current_date.month + 1)"
      ],
      "metadata": {
        "id": "lAePSEHv-kzY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for date in dates:\n",
        "    current_file = date+'.csv'\n",
        "    print(f\"Extracting for date: {date}\")\n",
        "    #url =''\n",
        "    url = 'https://en.tutiempo.net/climate/' + date + '/ws-417800.html'\n",
        "    print(f\"Hitting url : {url}\")\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        style_map = soup.find_all('style')\n",
        "        if len(style_map) > 1:\n",
        "            style_content = str(style_map[1])\n",
        "        else:\n",
        "            print(f\"No style map found for date: {date}\")\n",
        "            continue\n",
        "\n",
        "        css_classes = re.findall(r'\\.numspan span\\.(nt\\w+)::after\\{content:\"(.*?)\";', style_content)\n",
        "        replacement = {f'<span class=\"{cls}\"></span>': f'<span class=\"{cls}\">{content}</span>' for cls, content in css_classes}\n",
        "\n",
        "        all_tables = soup.find_all('table')\n",
        "        if len(all_tables) > 3:\n",
        "            table = all_tables[3]\n",
        "        else:\n",
        "            print(f\"No table found for date: {date}\")\n",
        "            continue\n",
        "\n",
        "        html_str = str(table)\n",
        "\n",
        "        for old, new in replacement.items():\n",
        "            html_str = html_str.replace(old, new)\n",
        "\n",
        "        updated_table = BeautifulSoup(html_str, 'html.parser')\n",
        "\n",
        "        if updated_table:\n",
        "            headers = [th.get_text(strip=True) for th in updated_table.find('tr').find_all('th')] if updated_table.find('tr') else []\n",
        "            if not headers:\n",
        "                print(f\"No headers found for date: {date}\")\n",
        "                continue\n",
        "\n",
        "            rows = []\n",
        "            for row in updated_table.find_all('tr')[1:]:\n",
        "                if row.th and row.th.has_attr('colspan'):\n",
        "                    continue  # Skip this row\n",
        "                cols = row.find_all('td')\n",
        "                row_data = [td.get_text(strip=True) for td in cols]\n",
        "                if row_data:\n",
        "                    rows.append(row_data)\n",
        "\n",
        "            df = pd.DataFrame(rows, columns=headers)\n",
        "            df.to_csv(current_file, index=False)\n",
        "        else:\n",
        "            print(f\"Could not update table for date: {date}\")\n",
        "\n",
        "    except requests.exceptions.HTTPError as e:\n",
        "        print(f\"HTTP Error for date {date}: {e}\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Request Exception for date {date}: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred for date {date}: {e}\")\n"
      ],
      "metadata": {
        "id": "hSrWpcTn-nDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "df = []\n",
        "merged_df = []\n",
        "for date in dates:\n",
        "    file_name = f\"{date}.csv\"\n",
        "    print(f\"Processing file: {file_name}\")\n",
        "    if not os.path.isfile(file_name):\n",
        "        print(f\"File {file_name} does not exist.\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        current_df = pd.read_csv(file_name)\n",
        "        current_df = current_df[:-1]\n",
        "        current_df['date'] = date\n",
        "        merged_df.append(current_df)\n",
        "\n",
        "    except pd.errors.EmptyDataError:\n",
        "        print(f\"No data in file {file_name}, skipping.\")\n",
        "    except pd.errors.ParserError:\n",
        "        print(f\"Parsing error in file {file_name}, skipping.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred while processing {file_name}: {e}\")\n",
        "\n",
        "df = pd.concat(merged_df, ignore_index=True)"
      ],
      "metadata": {
        "id": "iKBoMLzvD4D4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Day'] = df['Day'].astype(int).astype(str)\n",
        "df['date'] = df['Day'] + '-' + df['date']\n",
        "print(df)"
      ],
      "metadata": {
        "id": "XoRSQwTGLitB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail(30)"
      ],
      "metadata": {
        "id": "7vI-WcwLMzvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rename_columns = {\n",
        "    'T' : 'Average Temperature (°C)',\n",
        "    'TM': 'Maximum temperature (°C)',\n",
        "    'Tm': 'Minimum temperature (°C)',\n",
        "    'SLP':'Atmospheric pressure at sea level (hPa)',\n",
        "    'H' : 'Average relative humidity (%)',\n",
        "    'PP': 'Total rainfall (mm)',\n",
        "    'VV': 'Average visibility (Km)',\n",
        "    'V' : 'Average wind speed (Km/h)',\n",
        "    'VM': 'Maximum sustained wind speed (Km/h)',\n",
        "    'VG': 'Maximum speed of wind (Km/h)',\n",
        "    'RA': 'Total days it rained',\n",
        "    'SN': 'Total days that snowed',\n",
        "    'TS': 'Total days with thunderstorm',\n",
        "    'FG': 'Total days with fog',\n",
        "}\n",
        "df.rename(columns=rename_columns, inplace=True)"
      ],
      "metadata": {
        "id": "V-kayibGNgp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('WeatherData1942-2023.csv', index=False)"
      ],
      "metadata": {
        "id": "pQPNBES_EOwH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/WeatherData.zip /content/*.csv"
      ],
      "metadata": {
        "id": "I4eT04BPHXOO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}